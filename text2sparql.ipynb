{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text2SPARQL\n",
    "\n",
    "This is a development workbook for getting the hang of training models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"lcquad2\"\n",
    "DATASET_FOLDER = \"data\"\n",
    "DATASET_PATH = os.path.join(DATASET_FOLDER, DATASET_NAME)\n",
    "\n",
    "ACCELERATE_USE = False \n",
    "ACCELERATE_STR = \"-accelerate\" if ACCELERATE_USE else \"\"\n",
    "\n",
    "MODEL_NAME = \"t5-small\" # With t5-small, the non accelerated training works better than accelerated?\n",
    "MODEL_TYPE = \"text2sparql\"\n",
    "MODEL_FULL = f\"{MODEL_TYPE}-{MODEL_NAME}-{DATASET_NAME}{ACCELERATE_STR}\"\n",
    "\n",
    "MODEL_FOLDER = \"models\"\n",
    "MODEL_PATH = os.path.join(MODEL_FOLDER, MODEL_FULL)\n",
    "\n",
    "EVALUATION_FOLDER = os.path.join(MODEL_PATH, \"evaluations\")\n",
    "CHECKPOINT_FOLDER = os.path.join(MODEL_PATH, \"checkpoints\")\n",
    "\n",
    "folders = [MODEL_FOLDER, EVALUATION_FOLDER, CHECKPOINT_FOLDER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(DATASET_PATH)\n",
    "\n",
    "for folder in folders:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Bannerjee does some preprocessing of the LCQuAD dataset,\n",
    "I try to replicate that here.\n",
    "\n",
    "First we load some files into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'# Sample Entity Labels'\n",
      "['Chandrasekhar limit', 'toluene', 'Olympic victor, stadion']\n",
      "\n",
      "'# Sample Question, Query'\n",
      "[\"Who is the child of Ranavalona I's husband?\",\n",
      " 'SELECT ?answer WHERE { wd:Q169794 wdt:P26 ?X . ?X wdt:P22 ?answer}']\n",
      "\n",
      "'# Sample Relation Labels'\n",
      "['video', 'head of government']\n",
      "\n",
      "'# Sample SPARQL Vocab'\n",
      "['(', 'rdfs:label', 'by', 'ask']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import os\n",
    "from os.path import join\n",
    "from pprint import pprint\n",
    "\n",
    "assert DATASET_PATH.endswith(\"lcquad2\")\n",
    "lcquad2_dir = DATASET_PATH\n",
    "\n",
    "# LCQuAD2 entity labels\n",
    "with open(join(lcquad2_dir, \"lcq2_labels.pickle\"), \"rb\") as f:\n",
    "    labels = pickle.load(f)\n",
    "\n",
    "pprint(\"# Sample Entity Labels\")\n",
    "pprint(list(labels[k] for k in ['q51366', 'q15779', 'q23906217']))\n",
    "print()\n",
    "\n",
    "# Training Data has exactly the same file size as the official one\n",
    "with open(join(lcquad2_dir, \"train.json\")) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "pprint(\"# Sample Question, Query\")\n",
    "pprint(list(data[1][k] for k in [\"question\", \"sparql_wikidata\"]))\n",
    "print()\n",
    "\n",
    "# Load the relation labels\n",
    "with open(join(lcquad2_dir, \"relations.json\")) as f:\n",
    "    rel_labels = json.load(f)\n",
    "\n",
    "pprint(\"# Sample Relation Labels\")\n",
    "pprint(list(rel_labels[k] for k in [\"P10\", \"P6\"]))\n",
    "print()\n",
    "\n",
    "# Load the sparql vocabulary\n",
    "with open(join(lcquad2_dir, \"vocab.txt\")) as f:\n",
    "    vocab = list(map(lambda x: x.strip(), f.readlines()))\n",
    "    vocab.append('null') # not too sure what this is for\n",
    "\n",
    "pprint(\"# Sample SPARQL Vocab\")\n",
    "pprint(vocab[1:5])\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some labels are missing from the lcq2_labels.pickle,\n",
    "and cause run time errors in the script.\n",
    "We add them back here to avoid this problem\n",
    "(though ideally we should find a better label to entity map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['quercia']='null'\n",
    "labels['qui']='null'\n",
    "labels['}']='null'\n",
    "labels['p5122'] = 'Ontario public library ID'.lower()\n",
    "labels['p3888']='Boijmans artist ID'\n",
    "labels['p5388']='Bulgarian Antarctic Gazetteer ID'\n",
    "labels['p5151']='Israel Film Fund ID'\n",
    "labels['p3633']='British Museum place ID'\n",
    "labels['p1733']='Steam application ID'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we assign vocabularies to tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'# Sample Masked Tokens'\n",
      "['<extra_id_0>', '<extra_id_60>', '<extra_id_16>']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocab_dict = {}\n",
    "for i, text in enumerate(vocab):\n",
    "    vocab_dict[text] = f'<extra_id_{i}>'\n",
    "\n",
    "pprint(\"# Sample Masked Tokens\")\n",
    "pprint([vocab_dict[k] for k in ['\"', 'null', '?value']])\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And adjust some labels to use the null token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in labels:\n",
    "    if labels[k] is None:\n",
    "        labels[k] = vocab_dict['null']\n",
    "        # print(f'{k}: {labels[k]}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xprint(thing):\n",
    "    pprint(thing)\n",
    "    return thing\n",
    "\n",
    "def compare(x, y=None):\n",
    "\n",
    "    def _compare(z):\n",
    "        pprint(f\"Old: {x}\")\n",
    "        pprint(f\"New: {z}\")\n",
    "    \n",
    "    if not y:\n",
    "        return lambda z : _compare(z)\n",
    "    else:\n",
    "        return lambda : _compare(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we reformate the dataset\n",
    "- Note: it seems that Bannerjee replaces training data\n",
    "that has no questions with the Natural Language version.\n",
    "\n",
    "For reference these are the definition of each feature,\n",
    "taken **verbatim** from their [homepage](https://sda.tech/projects/lc-quad-2/)\n",
    "```\n",
    "{\n",
    "     \"uid\": a unique id number\n",
    "     \"sparql_wikidata\": a sparql fro wikidata endpoint\n",
    "     \"sparql_dbpedia18\": a sparql for DBpedia endpoint which has wikidata information\n",
    "     \"NNQT_question\": system generated question,\n",
    "     \"question\": Verbalised question,\n",
    "     \"paraphrased_question\": paraphrased version of the verbalised question,\n",
    "     \"template_id\": id for the template\n",
    "     \"template\": template discription    \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "data_x, data_y = [], []\n",
    "data_x_shuffle = []\n",
    "\n",
    "for i, inst in enumerate(data):\n",
    "    wikisparql = inst['sparql_wikidata']\n",
    "    if inst['question'] is None:\n",
    "        question = inst['NNQT_question']\n",
    "    else:\n",
    "        question = inst['question']\n",
    "    question = question.replace('{', '').replace('}', '')\n",
    "\n",
    "    match_str = r\"\\'(.*?)\\'\"\n",
    "    hashi = {}\n",
    "    # To mask filter literals\n",
    "    if re.search(match_str, wikisparql):\n",
    "        lits=re.findall(match_str,wikisparql)\n",
    "        # print(f\"Old: {wikisparql}\")\n",
    "        for j, lit in enumerate(lits):\n",
    "            idx = j + 1\n",
    "            wikisparql = wikisparql.replace(f\"'{lit.strip()}'\", f\"'###{idx}'\")\n",
    "            hashi[f'###{idx}'] = lit.strip()\n",
    "        # print(f\"New: {wikisparql}\")\n",
    "    \n",
    "    # there is an extra space beacuse of http: and https:\n",
    "    sparql = wikisparql.replace('(',' ( ').replace(')',' ) ') \\\n",
    "    .replace('{',' { '). \\\n",
    "    replace('}',' } ').replace('wd:','wd: ').replace('wdt:','wdt: '). \\\n",
    "    replace(' p:',' p: ').replace(' ps:',' ps: ').replace('pq:','pq: '). \\\n",
    "    replace(',',' , ').replace(\",'\",\", '\").replace(\"'\",\" ' \").replace('.',' . '). \\\n",
    "    replace('=',' = ').replace('  ',' ').lower()\n",
    "    \n",
    "    # print(f\"sparql: {sparql}\")\n",
    "    # select distinct ?obj where { wd: q188920 wdt: p2813 ?obj . ?obj wdt: p31 wd: q1002697 } \n",
    "\n",
    "    _ents = re.findall( r'wd: (?:.*?) ', sparql) # ['wd: q188920 ', 'wd: q1002697 ']\n",
    "    _ents_for_labels = re.findall( r'wd: (.*?) ', sparql) # ['q188920', 'q1002697']\n",
    "    \n",
    "    _rels = re.findall( r'wdt: (?:.*?) ',sparql)\n",
    "    _rels += re.findall( r' p: (?:.*?) ',sparql)\n",
    "    _rels += re.findall( r' ps: (?:.*?) ',sparql)\n",
    "    _rels += re.findall( r'pq: (?:.*?) ',sparql) # ['wdt: p2813 ', 'wdt: p31 ']\n",
    "    # Missing rdfs:label, not sure if that is important\n",
    "    \n",
    "    _rels_for_labels = re.findall( r'wdt: (.*?) ',sparql)\n",
    "    _rels_for_labels += re.findall( r' p: (.*?) ',sparql)\n",
    "    _rels_for_labels += re.findall( r' ps: (.*?) ',sparql)\n",
    "    _rels_for_labels += re.findall( r'pq: (.*?) ',sparql) # ['p2813', 'p31']\n",
    "\n",
    "    # print(_rels)\n",
    "    # print(_rels_for_labels)\n",
    "    for j in range(len(_ents_for_labels)):\n",
    "        # print('Q'+_ents_for_labels[j][1:])\n",
    "        if '}' in _ents[j]: # Entry 12686 is malformed\n",
    "            # pprint(inst)\n",
    "            # pprint(_ents)\n",
    "            _ents[j]=''\n",
    "        _ents[j]=_ents[j]+labels[_ents_for_labels[j]]+' '\n",
    "        # wd: q36970 -> wd: q36970 Jackie Chan\n",
    "\n",
    "    for j in range(len(_rels_for_labels)):\n",
    "        if _rels_for_labels[j].upper() not in rel_labels:\n",
    "            # For some reasons the original preprocess.py didnt convert to upper?\n",
    "            rel_labels['P'+_rels_for_labels[j][1:]]=vocab_dict['null']\n",
    "        _rels[j]=_rels[j]+rel_labels['P'+_rels_for_labels[j][1:]]+' '\n",
    "        # wdt: p26 -> wdt: p26 spouse\n",
    "    # print(_ents)\n",
    "\n",
    "    _ents+=_rels\n",
    "    # random.shuffle(_ents)\n",
    "    # random.shuffle(_rels)\n",
    "\n",
    "    # move to a function\n",
    "    newvars = ['?vr0','?vr1','?vr2','?vr3','?vr4','?vr5']\n",
    "    sparql_split = sparql.split()\n",
    "    variables = set([x for x in sparql_split if x[0] == '?'])\n",
    "    for j, var in enumerate(sorted(variables)):\n",
    "        if var == '?maskvar1': #???\n",
    "            print(sparql)\n",
    "            continue\n",
    "        sparql = sparql.replace(var, newvars[j]) # Normalize var names\n",
    "    \n",
    "    # old = compare(sparql)\n",
    "\n",
    "    split = sparql.split()\n",
    "    \n",
    "    for j, item in enumerate(split):\n",
    "        if item in vocab_dict:\n",
    "            split[j] = vocab_dict[item]\n",
    "    \n",
    "    split = ' '.join(split).strip()\n",
    "    # old(split)\n",
    "\n",
    "    for keys in hashi:\n",
    "        split = split.replace(keys, hashi[keys])\n",
    "    \n",
    "    data_y.append(split)\n",
    "\n",
    "    for rel in _ents:\n",
    "        rel=rel.replace('wd:',vocab_dict['wd:']+' ')\n",
    "        rel=rel.replace('wdt:',vocab_dict['wdt:']+' ')\n",
    "        old = compare(rel)\n",
    "        if 'p:' in rel:\n",
    "            if 'http' in rel:\n",
    "                print(inst) # There are no more http\n",
    "            rel=rel.replace('p:',vocab_dict['p:']+' ')\n",
    "            # old(rel)\n",
    "        rel=rel.replace('ps:',vocab_dict['ps:']+' ')\n",
    "        rel=rel.replace('pq:',vocab_dict['pq:']+' ')\n",
    "        question=question+' '+vocab_dict['[DEF]']+' '+rel # When question gets masked\n",
    "    data_x.append(question.strip())\n",
    "\n",
    "assert len(data_x) == len(data_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to save the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'x': data_x,\n",
    "    'y': data_y,\n",
    "    })\n",
    "\n",
    "save_file = join(lcquad2_dir, 'preprocessed_data.csv')\n",
    "df.to_csv(save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24180\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What periodical literature does Delta Air Line...</td>\n",
       "      <td>&lt;extra_id_6&gt; &lt;extra_id_21&gt; &lt;extra_id_39&gt; &lt;extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who is the child of Ranavalona I's husband? &lt;e...</td>\n",
       "      <td>&lt;extra_id_6&gt; &lt;extra_id_39&gt; &lt;extra_id_19&gt; &lt;extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is it true Jeff_Bridges occupation Lane Chandl...</td>\n",
       "      <td>&lt;extra_id_4&gt; &lt;extra_id_19&gt; &lt;extra_id_33&gt; &lt;extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the pre-requisite of phase matter of G...</td>\n",
       "      <td>&lt;extra_id_6&gt; &lt;extra_id_39&gt; &lt;extra_id_19&gt; &lt;extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which is the operating income for Qantas? &lt;ext...</td>\n",
       "      <td>&lt;extra_id_6&gt; &lt;extra_id_21&gt; &lt;extra_id_39&gt; &lt;extr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   x  \\\n",
       "0  What periodical literature does Delta Air Line...   \n",
       "1  Who is the child of Ranavalona I's husband? <e...   \n",
       "2  Is it true Jeff_Bridges occupation Lane Chandl...   \n",
       "3  What is the pre-requisite of phase matter of G...   \n",
       "4  Which is the operating income for Qantas? <ext...   \n",
       "\n",
       "                                                   y  \n",
       "0  <extra_id_6> <extra_id_21> <extra_id_39> <extr...  \n",
       "1  <extra_id_6> <extra_id_39> <extra_id_19> <extr...  \n",
       "2  <extra_id_4> <extra_id_19> <extra_id_33> <extr...  \n",
       "3  <extra_id_6> <extra_id_39> <extra_id_19> <extr...  \n",
       "4  <extra_id_6> <extra_id_21> <extra_id_39> <extr...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Now we need to generate a T5 model for fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import transformers\n",
    "# from accelerate import init_empty_weights, dispatch_model, infer_auto_device_map, load_checkpoint_and_dispatch\n",
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "\n",
    "model_name = MODEL_NAME # \"t5-small\"\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(Model, self).__init__()\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model_name, device_map=\"auto\")\n",
    "\n",
    "        pprint(\"# Model Device Map\")\n",
    "        pprint(self.model.hf_device_map)\n",
    "        print()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        outputs = self.model(\n",
    "            input_ids = input['input_ids'],\n",
    "            labels = input['labels'],\n",
    "            attention_mask = input['attention_mask'],\n",
    "            output_hidden_states = True,\n",
    "            output_attentions = True\n",
    "        )\n",
    "\n",
    "        return outputs.loss\n",
    "\n",
    "# model = T5ForConditionalGeneration.from_pretrained(model_name, device_map=\"auto\") # Device_map splits the load over multiple GPUs, this seems to be quite new"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "class Train:\n",
    "    def __init__(self,data,data_val, model_name):\n",
    "        self.data=data\n",
    "        self.dev_data=data_val\n",
    "\n",
    "        self.tokenizer=T5Tokenizer.from_pretrained(model_name)\n",
    "        self.model=Model(model_name)\n",
    "        # self.model.to(f'cuda:{self.model.device_ids[0]}')  \n",
    "           \n",
    "        # Modify lr?\n",
    "        self.optimizer=optim.AdamW(self.model.parameters(),lr=0.0015)\n",
    "        self.lr_scheduler=transformers. \\\n",
    "        get_polynomial_decay_schedule_with_warmup(self.optimizer, 5000, 30000,power=0.5)\n",
    "\n",
    "        self.iters=60000\n",
    "        self.print_every=100\n",
    "        self.eval_every=8000\n",
    "        # self.num_gpus=1\n",
    "        self.eval_bs=6\n",
    "        self.bs=5\n",
    "        self.back_propogate=10\n",
    "        \n",
    "        self.train()\n",
    "\n",
    "    def generate_batch(self):\n",
    "        output=random.sample(self.data,self.bs)\n",
    "        inp,label=[],[]\n",
    "        for dat in output:\n",
    "            inp.append(dat[0])\n",
    "            label.append(dat[1])\n",
    "\n",
    "        return inp,label\n",
    "\n",
    "    def preprocess_function(self,inputs, targets):\n",
    "        model_inputs=self.tokenizer(inputs, padding=True, \\\n",
    "                        return_tensors='pt',max_length=512, truncation=True)\n",
    "        labels=self.tokenizer(targets,padding=True,max_length=512, truncation=True)\n",
    "\n",
    "        if True:\n",
    "            labels[\"input_ids\"] = [\n",
    "            [(l if l != self.tokenizer.pad_token_id else -100) \\\n",
    "             for l in label] for label in labels[\"input_ids\"]\n",
    "            ]\n",
    "        labels['input_ids']=torch.tensor(labels['input_ids'])\n",
    "        model_inputs[\"labels\"]=labels[\"input_ids\"].to(0)\n",
    "        model_inputs[\"input_ids\"]=model_inputs[\"input_ids\"].to(0)\n",
    "        model_inputs[\"attention_mask\"]=model_inputs[\"attention_mask\"].to(0)\n",
    "\n",
    "        return model_inputs\n",
    "\n",
    "    def val(self,o):\n",
    "        pprint('# Validating...')\n",
    "        self.model.eval()\n",
    "        acc,bs,i=0,self.eval_bs,0\n",
    "        saver=[]\n",
    "\n",
    "        # progress_bar = tqdm.auto.tqdm(range(math.ceil(len(self.dev_data) / bs)))\n",
    "        # progress_bar.set_description(f\"Eval {o}\")\n",
    "           \n",
    "        while i<len(self.dev_data):\n",
    "            bs_=min(bs,len(self.dev_data)-i)\n",
    "            if i % (100) == 0:\n",
    "                print(f\"Evaluation {i}/{len(self.dev_data)}\")\n",
    "            i+=bs_\n",
    "            inp,label=[],[]\n",
    "            for j in range(i-bs_,i):\n",
    "                inp.append(self.dev_data[j][0])\n",
    "                label.append(self.dev_data[j][1])\n",
    "            \n",
    "\n",
    "            input=self.preprocess_function(inp,label)\n",
    "\n",
    "            output=self.model.model.generate(input_ids=input['input_ids'],\n",
    "                      num_beams=10,attention_mask=input['attention_mask'], \\\n",
    "                        early_stopping=True, max_length=200,output_hidden_states=True,output_attentions=True)\n",
    "            \n",
    "            out=self.tokenizer.batch_decode(output,skip_special_tokens=False)\n",
    "\n",
    "            for k in range(len(out)):\n",
    "                #print(out[k].replace('<pad>','').replace('</s>','').strip())\n",
    "                a1=out[k].replace('<pad>','').replace('</s>','').replace('<unk>','').replace('<s>','').strip().replace(' ','')\n",
    "                a2=label[k].strip().replace(' ','')\n",
    "                # print(a1, '       ', a2)\n",
    "                saver.append({'input':inp[k],'gold':label[k].strip(),'generated':out[k].replace('<pad>',''). \\\n",
    "                      replace('</s>','').replace('<unk>','').replace('<s>','').strip()})\n",
    "                if a1==a2:\n",
    "                    acc+=1; #print('ttt')\n",
    "\n",
    "            # progress_bar.update(1)\n",
    "        \n",
    "        file=open(join(EVALUATION_FOLDER, 'dev_result_'+str(o)+'.json'),'w')\n",
    "        json.dump(saver,file)\n",
    "        pprint(f'# Saved {file.name}')\n",
    "        file.close()\n",
    "        return 100*acc/len(self.dev_data)\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        scalar=0\n",
    "        for i in range(self.iters):\n",
    "            self.model.train()\n",
    "            inp,label=self.generate_batch()\n",
    "            input=self.preprocess_function(inp,label)\n",
    "            loss=self.model(input)\n",
    "\n",
    "            scalar+=loss.mean().item()\n",
    "            if(i+1)%self.print_every==0:\n",
    "                print('iteration={}, training loss={}'.format(i+1,scalar/self.print_every))\n",
    "                scalar=0\n",
    "            if(i + 1)%self.eval_every==0:\n",
    "                acc=self.val(i+1)\n",
    "                print('validation acc={}'.format(acc))\n",
    "\n",
    "                torch.save(self.model.state_dict(),\n",
    "                       join(CHECKPOINT_FOLDER,'checkpoint_'+str(i + 1)+'.pth'))\n",
    "                \n",
    "            loss/=self.back_propogate\n",
    "            loss.mean().backward()\n",
    "            if (i+1)%self.back_propogate:\n",
    "                self.optimizer.step();\n",
    "                self.lr_scheduler.step();\n",
    "                self.optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16926.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.values.tolist())*0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.values.tolist()\n",
    "total_len = len(data)\n",
    "split_len = round(total_len*0.3)\n",
    "final_data_dev, final_data = data[:split_len], data[split_len:]\n",
    "pprint(\"# Beginning training\")\n",
    "trainer = Train(final_data, final_data_dev, MODEL_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
