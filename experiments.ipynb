{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import json\n",
    "import tqdm\n",
    "import transformers\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from datasets import Dataset, DatasetDict\n",
    "import evaluate\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2\"\n",
    "NUM_EPOCHS = 10\n",
    "EXPERIMENT_NAME = \"t5-small_falcon2-default_annotation-k5\"\n",
    "EXPERIMENT_DIR = Path('experiments')\n",
    "MODEL_ARTIFACTS = EXPERIMENT_DIR / EXPERIMENT_NAME\n",
    "WEIGHTS_DIR = MODEL_ARTIFACTS / 'weights'\n",
    "VALS_DIR = MODEL_ARTIFACTS / 'validations'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make appropriate directoreis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "VALS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"t5-small\"\n",
    "tokenizer_path = \"t5-small\"\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path, device_map ='auto')\n",
    "tokenizer = T5Tokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define dataset maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df):\n",
    "  # ratios from Bannerjee\n",
    "  train = 0.7\n",
    "  dev = 0.1\n",
    "  test = 0.2\n",
    "  assert train + dev + test == 1.0\n",
    "  data_len = len(df)\n",
    "  train_set = Dataset.from_pandas(df[:round(data_len * train)])\n",
    "  dev_set = Dataset.from_pandas(df[round(data_len * train):round(data_len* (train + dev))])\n",
    "  test_set = Dataset.from_pandas(df[round(data_len * (train + dev)):])\n",
    "  \n",
    "  dataset = DatasetDict()\n",
    "  dataset['train'] = train_set\n",
    "  dataset['dev'] = dev_set\n",
    "  dataset['test'] = test_set\n",
    "\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define dataset tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(dataset, column):\n",
    "  print(\"tokenizing\")\n",
    "  model_inputs = tokenizer(dataset[column], padding=True, return_tensors=\"pt\")\n",
    "  return model_inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define unmasker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import T5Converter\n",
    "converter = T5Converter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(val_dataloader, val_path = None):\n",
    "  model.eval()\n",
    "  eval_dict = []\n",
    "\n",
    "  iters = len(val_dataloader)\n",
    "\n",
    "  progress_bar = tqdm.tqdm(iters)\n",
    "  progress_bar.set_description(f\"Eval\")\n",
    "\n",
    "  for val_batch in val_dataloader:\n",
    "    batch = {}\n",
    "    for k,v in val_batch.items():\n",
    "      if k in {\"input_ids\", \"labels\", \"attention_mask\"}:\n",
    "        batch[k] = v.to(\"cuda\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "      outputs = model(**batch)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    for i, pred in enumerate(tokenizer.batch_decode(predictions)):\n",
    "      gold = val_batch['gold'][i]\n",
    "      gold = gold.replace(\" \",\"\")\n",
    "      gold2 = gold.replace(\">\", \"> \").replace(\"<\",\" <\").replace(\"  \", \" \").strip()\n",
    "      pred = pred.replace(\" \",\"\").replace(\"</s>\", \"\").replace(\"<pad>\",\"\")\n",
    "      pred2 = pred.replace(\">\", \"> \").replace(\"<\",\" <\").replace(\"  \", \" \").strip()\n",
    "      eval_dict.append({\n",
    "        \"Utte\": val_batch['utterance'][i],\n",
    "        \"Anno\": val_batch['annotated'][i],\n",
    "        \"Gold\": val_batch['gold'][i],\n",
    "        \"Gene\": pred, # THIS NEEDS TO BE UNMASKED\n",
    "        \"Gol2\": converter._unmask_generic(gold2),\n",
    "        \"Gen2\": converter._unmask_generic(pred2),\n",
    "      })\n",
    "    progress_bar.update(1)\n",
    "  \n",
    "  if val_path:\n",
    "    with open(val_path, \"w\") as f:\n",
    "      json.dump(eval_dict, f, indent=2)\n",
    "  \n",
    "  model.train()\n",
    "  return eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def training_loop(df):\n",
    "  print(\"beginning training\")\n",
    "\n",
    "  assert 'utterance' in df.columns\n",
    "  assert 'annotated' in df.columns\n",
    "  assert 'gold' in df.columns\n",
    "\n",
    "  dataset = split_dataframe(df)\n",
    "  tokenized_dataset = dataset \\\n",
    "    .map(lambda x: tokenize_data(x, 'gold'), batched=True) \\\n",
    "    .rename_column('input_ids', 'labels') \\\n",
    "    .map(lambda x: tokenize_data(x, 'annotated'), batched=True)\n",
    "\n",
    "  tokenized_dataset.set_format(\"pt\", columns=[\"input_ids\", \"attention_mask\", \"labels\"], output_all_columns=True)\n",
    "  print(\"data loaded\")\n",
    "  \n",
    "  train_dataset = tokenized_dataset[\"train\"]\n",
    "  dev_dataset = tokenized_dataset[\"dev\"]\n",
    "  test_dataset = tokenized_dataset[\"test\"]\n",
    "\n",
    "  train_dataloader = DataLoader(train_dataset, batch_size = 1)\n",
    "  dev_dataloader = DataLoader(dev_dataset, batch_size = 1)\n",
    "\n",
    "  scalar = 0\n",
    "  i = 0\n",
    "\n",
    "  optimizer = optim.AdamW(model.parameters(), lr = 0.0015)\n",
    "  lr_scheduler=transformers. \\\n",
    "    get_polynomial_decay_schedule_with_warmup(optimizer, 5000, 30000, power=0.5)\n",
    "\n",
    "  for epoch in range(NUM_EPOCHS):\n",
    "    print(\"Beginning Epoch:\", epoch)\n",
    "    i = 0\n",
    "    iters = len(train_dataloader)\n",
    "    for batch in train_dataloader:\n",
    "      newbatch = {}\n",
    "      for k,v in batch.items():\n",
    "        if k in [\"labels\", \"input_ids\", \"attention_mask\"]:\n",
    "          newbatch[k] = v.to(\"cuda\")\n",
    "      \n",
    "      batch = newbatch\n",
    "      newbatch = {}\n",
    "\n",
    "      outputs = model(**batch)\n",
    "      loss = outputs.loss\n",
    "      scalar += loss.mean().item()\n",
    "\n",
    "      if (i + 1) % 100 == 0:\n",
    "        print(f'iteration = {i + 1}/{iters}, training loss={scalar/100}')\n",
    "        scalar = 0\n",
    "\n",
    "      loss /= 10 \n",
    "      loss.mean().backward()\n",
    "      if (i+1) % 10:\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "      \n",
    "      del batch\n",
    "      i += 1\n",
    "    \n",
    "    val(dev_dataloader, VALS_DIR / f\"val_{epoch}.json\")\n",
    "\n",
    "    torch.save(model.state_dict(),\n",
    "      WEIGHTS_DIR / f\"cp_{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'utterance': 'What is Delta Air Lines periodical literature mouthpiece?', 'ents': [{'uri': 'http://www.wikidata.org/entity/Q188920', 'prefix': 'wd:', 'id': 'Q188920'}, {'uri': 'http://www.wikidata.org/entity/Q1002697', 'prefix': 'wd:', 'id': 'Q1002697'}, {'uri': 'http://www.wikidata.org/entity/Q416938', 'prefix': 'wd:', 'id': 'Q416938'}, {'uri': 'http://www.wikidata.org/entity/Q523753', 'prefix': 'wd:', 'id': 'Q523753'}, {'uri': 'http://www.wikidata.org/entity/Q671722', 'prefix': 'wd:', 'id': 'Q671722'}], 'rels': []}, {'utterance': 'What is Delta Air Lines periodical literature mouthpiece?', 'fragments': ['[DEF]', 'wd:', 'Q188920 Delta', '[DEF]', 'wd:', 'Q1002697 periodical literature', '[DEF]', 'wd:', 'Q416938 Mouthpiece', '[DEF]', 'wd:', 'Q523753 mouthpiece', '[DEF]', 'wd:', 'Q671722 mouthpiece']}, {'inputs': 'What is Delta Air Lines periodical literature mouthpiece? <extra_id_59> <extra_id_53> Q188920 Delta <extra_id_59> <extra_id_53> Q1002697 periodical literature <extra_id_59> <extra_id_53> Q416938 Mouthpiece <extra_id_59> <extra_id_53> Q523753 mouthpiece <extra_id_59> <extra_id_53> Q671722 mouthpiece', 'labels': '<extra_id_6> <extra_id_21> <extra_id_39> <extra_id_19> <extra_id_33> <extra_id_53> q188920 <extra_id_54> p2813 <extra_id_39> <extra_id_38> <extra_id_39> <extra_id_54> p31 <extra_id_53> q1002697 <extra_id_15>'}]\n"
     ]
    }
   ],
   "source": [
    "df_json = []\n",
    "with open('falcon_links/2/link_24066.json') as f:\n",
    "  data_json = json.load(f)\n",
    "\n",
    "print(data_json[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_json = []\n",
    "# with open('weekend.json') as f:\n",
    "#   data_json = json.load(f)\n",
    "\n",
    "for data in data_json:\n",
    "  data_dict = {\n",
    "    \"utterance\": data[0][\"utterance\"],\n",
    "    \"annotated\": data[2][\"inputs\"],\n",
    "    \"gold\": data[2][\"labels\"]\n",
    "  }\n",
    "  df_json.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>annotated</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is Delta Air Lines periodical literature ...</td>\n",
       "      <td>What is Delta Air Lines periodical literature ...</td>\n",
       "      <td>&lt;extra_id_6&gt; &lt;extra_id_21&gt; &lt;extra_id_39&gt; &lt;extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the name of Ranavalona Is husbands child?</td>\n",
       "      <td>What is the name of Ranavalona Is husbands chi...</td>\n",
       "      <td>&lt;extra_id_6&gt; &lt;extra_id_39&gt; &lt;extra_id_19&gt; &lt;extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Are Jeff Bridges and Lane Chandler both photog...</td>\n",
       "      <td>Are Jeff Bridges and Lane Chandler both photog...</td>\n",
       "      <td>&lt;extra_id_4&gt; &lt;extra_id_19&gt; &lt;extra_id_33&gt; &lt;extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What range are the papers at the Monique Genon...</td>\n",
       "      <td>What range are the papers at the Monique Genon...</td>\n",
       "      <td>&lt;extra_id_6&gt; &lt;extra_id_39&gt; &lt;extra_id_19&gt; &lt;extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which is the operating income for Qantas?</td>\n",
       "      <td>Which is the operating income for Qantas? &lt;ext...</td>\n",
       "      <td>&lt;extra_id_6&gt; &lt;extra_id_21&gt; &lt;extra_id_39&gt; &lt;extr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           utterance  \\\n",
       "0  What is Delta Air Lines periodical literature ...   \n",
       "1  What is the name of Ranavalona Is husbands child?   \n",
       "2  Are Jeff Bridges and Lane Chandler both photog...   \n",
       "3  What range are the papers at the Monique Genon...   \n",
       "4          Which is the operating income for Qantas?   \n",
       "\n",
       "                                           annotated  \\\n",
       "0  What is Delta Air Lines periodical literature ...   \n",
       "1  What is the name of Ranavalona Is husbands chi...   \n",
       "2  Are Jeff Bridges and Lane Chandler both photog...   \n",
       "3  What range are the papers at the Monique Genon...   \n",
       "4  Which is the operating income for Qantas? <ext...   \n",
       "\n",
       "                                                gold  \n",
       "0  <extra_id_6> <extra_id_21> <extra_id_39> <extr...  \n",
       "1  <extra_id_6> <extra_id_39> <extra_id_19> <extr...  \n",
       "2  <extra_id_4> <extra_id_19> <extra_id_33> <extr...  \n",
       "3  <extra_id_6> <extra_id_39> <extra_id_19> <extr...  \n",
       "4  <extra_id_6> <extra_id_21> <extra_id_39> <extr...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(df_json)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loop(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
