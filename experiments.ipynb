{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import json\n",
    "import tqdm\n",
    "import transformers\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from datasets import Dataset, DatasetDict\n",
    "import evaluate\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "NUM_EPOCHS = 50\n",
    "EXPERIMENT_NAME = \"t5-small_falcon2-default_annotation-k5\"\n",
    "EXPERIMENT_DIR = Path('experiments')\n",
    "MODEL_ARTIFACTS = EXPERIMENT_DIR / EXPERIMENT_NAME\n",
    "WEIGHTS_DIR = MODEL_ARTIFACTS / 'weights'\n",
    "VALS_DIR = MODEL_ARTIFACTS / 'validations'\n",
    "LINKS_PATH = 'falcon_links/2/link_24066.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make appropriate directoreis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "VALS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"t5-small\"\n",
    "tokenizer_path = \"t5-small\"\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path, device_map ='auto')\n",
    "tokenizer = T5Tokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(model.hf_device_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define dataset maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df):\n",
    "  # ratios from Bannerjee\n",
    "  train = 0.7\n",
    "  dev = 0.1\n",
    "  test = 0.2\n",
    "  assert train + dev + test == 1.0\n",
    "  data_len = len(df)\n",
    "  train_set = Dataset.from_pandas(df[:round(data_len * train)])\n",
    "  dev_set = Dataset.from_pandas(df[round(data_len * train):round(data_len* (train + dev))])\n",
    "  test_set = Dataset.from_pandas(df[round(data_len * (train + dev)):])\n",
    "  \n",
    "  dataset = DatasetDict()\n",
    "  dataset['train'] = train_set\n",
    "  dataset['dev'] = dev_set\n",
    "  dataset['test'] = test_set\n",
    "\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define dataset tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(dataset, column):\n",
    "  model_inputs = tokenizer(dataset[column], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "  return model_inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define unmasker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import T5Converter\n",
    "converter = T5Converter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(val_dataloader, val_path = None):\n",
    "  model.eval()\n",
    "  eval_dict = []\n",
    "\n",
    "  iters = len(val_dataloader)\n",
    "\n",
    "  progress_bar = tqdm.tqdm(iters, bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt}\")\n",
    "  progress_bar.set_description(f\"Eval\")\n",
    "\n",
    "  correct_preds = 0\n",
    "  total_preds = 0\n",
    "\n",
    "  for val_batch in val_dataloader:\n",
    "    batch = {}\n",
    "    for k,v in val_batch.items():\n",
    "      if k in {\"input_ids\", \"labels\", \"attention_mask\"}:\n",
    "        batch[k] = v.to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "      outputs = model(**batch)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    for i, pred in enumerate(tokenizer.batch_decode(predictions)):\n",
    "      gold = val_batch['gold'][i]\n",
    "      gold = gold.strip().replace(\" \",\"\")\n",
    "      gold2 = gold.replace(\">\", \"> \").replace(\"<\",\" <\").replace(\"  \", \" \").strip()\n",
    "      pred = pred.replace(\" \",\"\").replace(\"</s>\", \"\").replace(\"<pad>\",\"\").replace('<unk>','').replace('<s>','').strip().replace(\" \",\"\")\n",
    "      pred2 = pred.replace(\">\", \"> \").replace(\"<\",\" <\").replace(\"  \", \" \").strip()\n",
    "      entry_dict = {\n",
    "        \"Utte\": val_batch['utterance'][i],\n",
    "        \"Anno\": val_batch['annotated'][i],\n",
    "        \"Gold\": val_batch['gold'][i],\n",
    "        \"Gene\": pred, # THIS NEEDS TO BE UNMASKED\n",
    "        \"Gol2\": converter._unmask_generic(gold2),\n",
    "        \"Gen2\": converter._unmask_generic(pred2),\n",
    "      }\n",
    "      eval_dict.append(entry_dict)\n",
    "      total_preds += 1\n",
    "      if entry_dict['Gol2'] == entry_dict['Gen2']:\n",
    "        correct_preds += 1\n",
    "    progress_bar.update(1)\n",
    "  \n",
    "  if val_path:\n",
    "    with open(val_path, \"w\") as f:\n",
    "      json.dump(eval_dict, f, indent=2)\n",
    "\n",
    "  accuracy = correct_preds/total_preds\n",
    "\n",
    "  meta = {\n",
    "    'accuracy': accuracy\n",
    "  }\n",
    "  \n",
    "  model.train()\n",
    "  return eval_dict, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(df):\n",
    "  print(\"beginning training\")\n",
    "\n",
    "  assert 'utterance' in df.columns\n",
    "  assert 'annotated' in df.columns\n",
    "  assert 'gold' in df.columns\n",
    "\n",
    "  dataset = split_dataframe(df)\n",
    "  tokenized_dataset = dataset \\\n",
    "    .map(lambda x: tokenize_data(x, 'gold'), batched=True) \\\n",
    "    .rename_column('input_ids', 'labels') \\\n",
    "    .map(lambda x: tokenize_data(x, 'annotated'), batched=True)\n",
    "\n",
    "  tokenized_dataset.set_format(\"pt\", columns=[\"input_ids\", \"attention_mask\", \"labels\"], output_all_columns=True)\n",
    "  print(\"data loaded\")\n",
    "  \n",
    "  train_dataset = tokenized_dataset[\"train\"]\n",
    "  dev_dataset = tokenized_dataset[\"dev\"]\n",
    "  test_dataset = tokenized_dataset[\"test\"]\n",
    "\n",
    "  train_dataloader = DataLoader(train_dataset, batch_size = 10)\n",
    "  dev_dataloader = DataLoader(dev_dataset, batch_size = 10)\n",
    "\n",
    "  scalar = 0\n",
    "\n",
    "  optimizer = optim.AdamW(model.parameters(), lr = 0.0015)\n",
    "  lr_scheduler=transformers. \\\n",
    "    get_polynomial_decay_schedule_with_warmup(optimizer, 5000, 30000, power=0.5)\n",
    "  \n",
    "  epoch_data = {}\n",
    "\n",
    "  for epoch in range(NUM_EPOCHS):\n",
    "    print(\"Beginning Epoch:\", epoch)\n",
    "    i = 0\n",
    "    iters = len(train_dataloader)\n",
    "    for batch in train_dataloader:\n",
    "      newbatch = {}\n",
    "      for k,v in batch.items():\n",
    "        if k in [\"labels\", \"input_ids\", \"attention_mask\"]:\n",
    "          newbatch[k] = v.to(\"cuda\")\n",
    "      \n",
    "      batch = newbatch\n",
    "      newbatch = {}\n",
    "\n",
    "      outputs = model(**batch)\n",
    "      loss = outputs.loss\n",
    "      scalar += loss.mean().item()\n",
    "\n",
    "      if (i+1) % 100 == 0:\n",
    "        print(f'iteration = {i+1}/{iters}, training loss={scalar/100}')\n",
    "        scalar = 0\n",
    "\n",
    "      loss /= 10 \n",
    "      loss.mean().backward()\n",
    "      if (i+1) % 1 == 0:\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "      \n",
    "      del batch\n",
    "      i += 1\n",
    "    \n",
    "    print(f\"Validating epoch {epoch}\")\n",
    "    val_filename = f\"val_{epoch}.json\"\n",
    "    _, acc = val(dev_dataloader, VALS_DIR / val_filename)\n",
    "    print(f\"Accuracy: {acc:.2f}\")\n",
    "    assert val_filename not in epoch_data\n",
    "    epoch_data[val_filename] = {\"accuracy\": acc}\n",
    "\n",
    "    with open(MODEL_ARTIFACTS / \"meta_data.json\", \"w\") as f:\n",
    "      json.dump(epoch_data, f, indent=2)\n",
    "\n",
    "    torch.save(model.state_dict(),\n",
    "      WEIGHTS_DIR / f\"cp_{epoch}.pth\")\n",
    "  print(f\"Validating final\")\n",
    "  val_filename = f\"val_final.json\"\n",
    "\n",
    "  _, meta = val(dev_dataloader, VALS_DIR / val_filename)\n",
    "\n",
    "  epoch_data[val_filename] = {\"accuracy\": acc}\n",
    "\n",
    "  with open(MODEL_ARTIFACTS / \"meta_data.json\", \"w\") as f:\n",
    "    json.dump(epoch_data, f, indent=2)\n",
    "\n",
    "  torch.save(model.state_dict(),\n",
    "    WEIGHTS_DIR / f\"cp_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json = []\n",
    "with open(LINKS_PATH) as f:\n",
    "  data_json = json.load(f)\n",
    "\n",
    "print(data_json[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_json = []\n",
    "# with open('weekend.json') as f:\n",
    "#   data_json = json.load(f)\n",
    "\n",
    "for data in data_json:\n",
    "  data_dict = {\n",
    "    \"utterance\": data[0][\"utterance\"],\n",
    "    \"annotated\": data[2][\"inputs\"],\n",
    "    \"gold\": data[2][\"labels\"]\n",
    "  }\n",
    "  df_json.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(df_json)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loop(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import time\n",
    "\n",
    "pb = tqdm.tqdm(total=5, bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt}\")\n",
    "\n",
    "for i in range(5):\n",
    "  time.sleep(1)\n",
    "  pb.update(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
