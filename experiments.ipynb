{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import json\n",
    "import tqdm\n",
    "import transformers\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from datasets import Dataset, DatasetDict\n",
    "import evaluate\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "NUM_EPOCHS = 5\n",
    "EXPERIMENT_NAME = \"t5-small_falcon2-default_annotation-default_testrun\"\n",
    "EXPERIMENT_DIR = Path('experiments')\n",
    "MODEL_ARTIFACTS = EXPERIMENT_DIR / EXPERIMENT_NAME\n",
    "WEIGHTS_DIR = MODEL_ARTIFACTS / 'weights'\n",
    "VALS_DIR = MODEL_ARTIFACTS / 'validations'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make appropriate directoreis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "VALS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"t5-small\"\n",
    "tokenizer_path = \"t5-small\"\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path).to(\"cuda\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define dataset maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df):\n",
    "  # ratios from Bannerjee\n",
    "  train = 0.7\n",
    "  dev = 0.1\n",
    "  test = 0.2\n",
    "  assert train + dev + test == 1.0\n",
    "  data_len = len(df)\n",
    "  train_set = Dataset.from_pandas(df[:round(data_len * train)])\n",
    "  dev_set = Dataset.from_pandas(df[round(data_len * train):round(data_len* (train + dev))])\n",
    "  test_set = Dataset.from_pandas(df[round(data_len * (train + dev)):])\n",
    "  \n",
    "  dataset = DatasetDict()\n",
    "  dataset['train'] = train_set\n",
    "  dataset['dev'] = dev_set\n",
    "  dataset['test'] = test_set\n",
    "\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define dataset tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(dataset, column):\n",
    "  print(\"tokenizing\")\n",
    "  model_inputs = tokenizer(dataset[column], padding=True, return_tensors=\"pt\")\n",
    "  return model_inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define unmasker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import T5Converter\n",
    "converter = T5Converter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(val_dataloader, val_path = None):\n",
    "  model.eval()\n",
    "  eval_dict = []\n",
    "\n",
    "  iters = len(val_dataloader)\n",
    "\n",
    "  progress_bar = tqdm.tqdm(iters)\n",
    "  progress_bar.set_description(f\"Eval\")\n",
    "\n",
    "  for val_batch in val_dataloader:\n",
    "    batch = {}\n",
    "    for k,v in val_batch.items():\n",
    "      if k in {\"input_ids\", \"labels\", \"attention_mask\"}:\n",
    "        batch[k] = v.to(\"cuda\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "      outputs = model(**batch)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    for i, pred in enumerate(tokenizer.batch_decode(predictions)):\n",
    "      gold = val_batch['gold'][i]\n",
    "      gold = gold.replace(\" \",\"\")\n",
    "      gold2 = gold.replace(\">\", \"> \").replace(\"<\",\" <\").replace(\"  \", \" \").strip()\n",
    "      pred = pred.replace(\" \",\"\").replace(\"</s>\", \"\").replace(\"<pad>\",\"\")\n",
    "      pred2 = pred.replace(\">\", \"> \").replace(\"<\",\" <\").replace(\"  \", \" \").strip()\n",
    "      eval_dict.append({\n",
    "        \"Utte\": val_batch['utterance'][i],\n",
    "        \"Anno\": val_batch['annotated'][i],\n",
    "        \"Gold\": val_batch['gold'][i],\n",
    "        \"Gene\": pred, # THIS NEEDS TO BE UNMASKED\n",
    "        \"Gol2\": converter._unmask_generic(gold2),\n",
    "        \"Gen2\": converter._unmask_generic(pred2),\n",
    "      })\n",
    "    progress_bar.update(1)\n",
    "  \n",
    "  if val_path:\n",
    "    with open(val_path, \"w\") as f:\n",
    "      json.dump(eval_dict, f, indent=2)\n",
    "  \n",
    "  model.train()\n",
    "  return eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(df):\n",
    "  print(\"beginning training\")\n",
    "\n",
    "  assert 'utterance' in df.columns\n",
    "  assert 'annotated' in df.columns\n",
    "  assert 'gold' in df.columns\n",
    "\n",
    "  dataset = split_dataframe(df)\n",
    "  tokenized_dataset = dataset \\\n",
    "    .map(lambda x: tokenize_data(x, 'gold'), batched=True) \\\n",
    "    .rename_column('input_ids', 'labels') \\\n",
    "    .map(lambda x: tokenize_data(x, 'annotated'), batched=True)\n",
    "\n",
    "  tokenized_dataset.set_format(\"pt\", columns=[\"input_ids\", \"attention_mask\", \"labels\"], output_all_columns=True)\n",
    "  print(\"data loaded\")\n",
    "  \n",
    "  train_dataset = tokenized_dataset[\"train\"]\n",
    "  dev_dataset = tokenized_dataset[\"dev\"]\n",
    "  test_dataset = tokenized_dataset[\"test\"]\n",
    "\n",
    "  train_dataloader = DataLoader(train_dataset, batch_size = 2)\n",
    "  dev_dataloader = DataLoader(dev_dataset, batch_size = 2)\n",
    "\n",
    "  scalar = 0\n",
    "  i = 0\n",
    "\n",
    "  optimizer = optim.AdamW(model.parameters(), lr = 0.0015)\n",
    "  lr_scheduler=transformers. \\\n",
    "    get_polynomial_decay_schedule_with_warmup(optimizer, 5000, 30000, power=0.5)\n",
    "\n",
    "  for epoch in range(NUM_EPOCHS):\n",
    "    print(\"Beginning Epoch:\", epoch)\n",
    "    i = 0\n",
    "    iters = len(train_dataloader)\n",
    "    for batch in train_dataloader:\n",
    "      newbatch = {}\n",
    "      for k,v in batch.items():\n",
    "        if k in [\"labels\", \"input_ids\", \"attention_mask\"]:\n",
    "          newbatch[k] = v.to(\"cuda\")\n",
    "      \n",
    "      batch = newbatch\n",
    "\n",
    "      outputs = model(**batch)\n",
    "      loss = outputs.loss\n",
    "      scalar += loss.mean().item()\n",
    "\n",
    "      if (i + 1) % 100 == 0:\n",
    "        print(f'iteration = {i + 1}/{iters}, training loss={scalar/100}')\n",
    "        scalar = 0\n",
    "\n",
    "      loss /= 10 \n",
    "      loss.mean().backward()\n",
    "      if (i+1) % 10:\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "      \n",
    "      i += 1\n",
    "    \n",
    "    val(dev_dataloader, VALS_DIR / f\"val_{epoch}.json\")\n",
    "\n",
    "    torch.save(model.state_dict(),\n",
    "      WEIGHTS_DIR / f\"cp_{epoch}.pth\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json = []\n",
    "with open('weekend.json') as f:\n",
    "  data_json = json.load(f)\n",
    "\n",
    "for data in data_json:\n",
    "  data_dict = {\n",
    "    \"utterance\": data[0][\"utterance\"],\n",
    "    \"annotated\": data[2][\"inputs\"],\n",
    "    \"gold\": data[2][\"labels\"]\n",
    "  }\n",
    "  df_json.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>annotated</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What periodical literature does Delta Air Line...</td>\n",
       "      <td>What periodical literature does Delta Air Line...</td>\n",
       "      <td>&lt;extra_id_6&gt; &lt;extra_id_21&gt; &lt;extra_id_39&gt; &lt;extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who is the child of Ranavalona I's husband?</td>\n",
       "      <td>Who is the child of Ranavalona I's husband? &lt;e...</td>\n",
       "      <td>&lt;extra_id_6&gt; &lt;extra_id_39&gt; &lt;extra_id_19&gt; &lt;extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is it true Jeff_Bridges occupation Lane Chandl...</td>\n",
       "      <td>Is it true Jeff_Bridges occupation Lane Chandl...</td>\n",
       "      <td>&lt;extra_id_4&gt; &lt;extra_id_19&gt; &lt;extra_id_33&gt; &lt;extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the pre-requisite of phase matter of G...</td>\n",
       "      <td>What is the pre-requisite of phase matter of G...</td>\n",
       "      <td>&lt;extra_id_6&gt; &lt;extra_id_39&gt; &lt;extra_id_19&gt; &lt;extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which is the operating income for Qantas?</td>\n",
       "      <td>Which is the operating income for Qantas? &lt;ext...</td>\n",
       "      <td>&lt;extra_id_6&gt; &lt;extra_id_21&gt; &lt;extra_id_39&gt; &lt;extr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           utterance  \\\n",
       "0  What periodical literature does Delta Air Line...   \n",
       "1        Who is the child of Ranavalona I's husband?   \n",
       "2  Is it true Jeff_Bridges occupation Lane Chandl...   \n",
       "3  What is the pre-requisite of phase matter of G...   \n",
       "4          Which is the operating income for Qantas?   \n",
       "\n",
       "                                           annotated  \\\n",
       "0  What periodical literature does Delta Air Line...   \n",
       "1  Who is the child of Ranavalona I's husband? <e...   \n",
       "2  Is it true Jeff_Bridges occupation Lane Chandl...   \n",
       "3  What is the pre-requisite of phase matter of G...   \n",
       "4  Which is the operating income for Qantas? <ext...   \n",
       "\n",
       "                                                gold  \n",
       "0  <extra_id_6> <extra_id_21> <extra_id_39> <extr...  \n",
       "1  <extra_id_6> <extra_id_39> <extra_id_19> <extr...  \n",
       "2  <extra_id_4> <extra_id_19> <extra_id_33> <extr...  \n",
       "3  <extra_id_6> <extra_id_39> <extra_id_19> <extr...  \n",
       "4  <extra_id_6> <extra_id_21> <extra_id_39> <extr...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(df_json)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c61d55fe6c40dcbc6d5ef9662e9f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2cc02355e1c4a47bd5cc1c7a49eba4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a22efbe40c94152881cf916bed7394c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608bd4f663004a42be357c8f9bb47331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b808327d65417ea7789fcd5e2a1217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a682ef28b0045daa95b4e34e3cadedc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing\n",
      "data loaded\n",
      "Beginning Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: : 1it [00:00, 27.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: : 1it [00:00, 39.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: : 1it [00:00, 30.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: : 1it [00:00, 26.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: : 1it [00:00, 25.72it/s]\n"
     ]
    }
   ],
   "source": [
    "training_loop(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
