{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import json\n",
    "import tqdm\n",
    "import transformers\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from datasets import Dataset, DatasetDict\n",
    "import evaluate\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "NUM_EPOCHS = 1\n",
    "EXPERIMENT_NAME = \"t5-small_falcon2-5eg0r\"\n",
    "EXPERIMENT_DIR = Path('experiments')\n",
    "MODEL_ARTIFACTS = EXPERIMENT_DIR / EXPERIMENT_NAME\n",
    "WEIGHTS_DIR = MODEL_ARTIFACTS / 'weights'\n",
    "VALS_DIR = MODEL_ARTIFACTS / 'validations'\n",
    "LINKS_PATH = 'falcon_links/5ents-gold_0rels/link_28246.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make appropriate directoreis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "VALS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"t5-small\"\n",
    "tokenizer_path = \"t5-small\"\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path, device_map ='auto')\n",
    "tokenizer = T5Tokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 0}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(model.hf_device_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define dataset maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df):\n",
    "  # ratios from Bannerjee\n",
    "  train = 0.7\n",
    "  dev = 0.1\n",
    "  test = 0.2\n",
    "  assert train + dev + test == 1.0\n",
    "  data_len = len(df)\n",
    "  train_set = Dataset.from_pandas(df[:round(data_len * train)])\n",
    "  dev_set = Dataset.from_pandas(df[round(data_len * train):round(data_len* (train + dev))])\n",
    "  test_set = Dataset.from_pandas(df[round(data_len * (train + dev)):])\n",
    "  \n",
    "  dataset = DatasetDict()\n",
    "  dataset['train'] = train_set\n",
    "  dataset['dev'] = dev_set\n",
    "  dataset['test'] = test_set\n",
    "\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define dataset tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(dataset, column):\n",
    "  model_inputs = tokenizer(dataset[column], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "  return model_inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define unmasker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import T5Converter\n",
    "converter = T5Converter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(val_dataloader, val_path = None):\n",
    "  model.eval()\n",
    "  eval_dict = []\n",
    "\n",
    "  iters = len(val_dataloader)\n",
    "\n",
    "  # progress_bar = tqdm.tqdm(iters, bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt}\")\n",
    "  # progress_bar.set_description(f\"Eval\")\n",
    "\n",
    "  correct_preds = 0\n",
    "  total_preds = 0\n",
    "\n",
    "  for val_batch in val_dataloader:\n",
    "    batch = {}\n",
    "    for k,v in val_batch.items():\n",
    "      if k in {\"input_ids\", \"attention_mask\"}:\n",
    "        batch[k] = v.to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "      outputs = model.generate(**batch, num_beams=10, max_length=200,\n",
    "        output_hidden_states=True, output_attentions=True, early_stopping=True)\n",
    "    \n",
    "    for i, pred in enumerate(tokenizer.batch_decode(outputs, skip_special_tokens=False)):\n",
    "      gold = val_batch['gold'][i]\n",
    "      gold = gold.strip().replace(\" \",\"\")\n",
    "      gold2 = gold.replace(\">\", \"> \").replace(\"<\",\" <\").replace(\"  \", \" \").strip()\n",
    "      pred = pred.replace(\" \",\"\").replace(\"</s>\", \"\").replace(\"<pad>\",\"\").replace('<unk>','').replace('<s>','').strip().replace(\" \",\"\")\n",
    "      pred2 = pred.replace(\">\", \"> \").replace(\"<\",\" <\").replace(\"  \", \" \").strip()\n",
    "      entry_dict = {\n",
    "        \"Utte\": val_batch['utterance'][i],\n",
    "        \"Anno\": val_batch['annotated'][i],\n",
    "        \"Gold\": val_batch['gold'][i],\n",
    "        \"Gene\": pred, # THIS NEEDS TO BE UNMASKED\n",
    "        \"Gol2\": converter._unmask_generic(gold2),\n",
    "        \"Gen2\": converter._unmask_generic(pred2),\n",
    "      }\n",
    "      eval_dict.append(entry_dict)\n",
    "      total_preds += 1\n",
    "      if entry_dict['Gol2'] == entry_dict['Gen2']:\n",
    "        correct_preds += 1\n",
    "    # progress_bar.update(1)\n",
    "  \n",
    "  if val_path:\n",
    "    with open(val_path, \"w\") as f:\n",
    "      json.dump(eval_dict, f, indent=2)\n",
    "\n",
    "  accuracy = correct_preds/total_preds\n",
    "\n",
    "  meta = {\n",
    "    'accuracy': f\"{accuracy:.10f}\"\n",
    "  }\n",
    "  \n",
    "  model.train()\n",
    "  return eval_dict, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(df):\n",
    "  print(\"beginning training\")\n",
    "\n",
    "  assert 'utterance' in df.columns\n",
    "  assert 'annotated' in df.columns\n",
    "  assert 'gold' in df.columns\n",
    "\n",
    "  dataset = split_dataframe(df)\n",
    "  tokenized_dataset = dataset \\\n",
    "    .map(lambda x: tokenize_data(x, 'gold'), batched=True) \\\n",
    "    .rename_column('input_ids', 'labels') \\\n",
    "    .map(lambda x: tokenize_data(x, 'annotated'), batched=True)\n",
    "\n",
    "  tokenized_dataset.set_format(\"pt\", columns=[\"input_ids\", \"attention_mask\", \"labels\"], output_all_columns=True)\n",
    "  print(\"data loaded\")\n",
    "  \n",
    "  train_dataset = tokenized_dataset[\"train\"]\n",
    "  dev_dataset = tokenized_dataset[\"dev\"]\n",
    "  test_dataset = tokenized_dataset[\"test\"]\n",
    "\n",
    "  train_dataloader = DataLoader(train_dataset, batch_size = 10)\n",
    "  dev_dataloader = DataLoader(dev_dataset, batch_size = 10)\n",
    "\n",
    "  scalar = 0\n",
    "\n",
    "  optimizer = optim.AdamW(model.parameters(), lr = 0.0015)\n",
    "  lr_scheduler=transformers. \\\n",
    "    get_polynomial_decay_schedule_with_warmup(optimizer, 5000, 30000, power=0.5)\n",
    "  \n",
    "  epoch_data = {}\n",
    "\n",
    "  for epoch in range(NUM_EPOCHS):\n",
    "    print(\"\\nBeginning Epoch:\", epoch)\n",
    "    i = 0\n",
    "    iters = len(train_dataloader)\n",
    "    for batch in train_dataloader:\n",
    "      newbatch = {}\n",
    "      for k,v in batch.items():\n",
    "        if k in [\"labels\", \"input_ids\", \"attention_mask\"]:\n",
    "          newbatch[k] = v.to(\"cuda\")\n",
    "      \n",
    "      batch = newbatch\n",
    "      newbatch = {}\n",
    "\n",
    "      outputs = model(**batch)\n",
    "      loss = outputs.loss\n",
    "      scalar += loss.mean().item()\n",
    "\n",
    "      if (i+1) % 100 == 0:\n",
    "        print(f'iteration = {i+1}/{iters}, training loss={scalar/100}')\n",
    "        scalar = 0\n",
    "\n",
    "      loss /= 10 \n",
    "      loss.mean().backward()\n",
    "      if (i+1) % 1 == 0:\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "      \n",
    "      del batch\n",
    "      i += 1\n",
    "    \n",
    "    print(f\"Validating epoch {epoch}\")\n",
    "    val_filename = f\"val_{epoch}.json\"\n",
    "    _, meta = val(dev_dataloader, VALS_DIR / val_filename)\n",
    "    pprint(meta)\n",
    "    assert val_filename not in epoch_data\n",
    "    epoch_data[val_filename] = meta\n",
    "\n",
    "    with open(MODEL_ARTIFACTS / \"meta_data.json\", \"w\") as f:\n",
    "      json.dump(epoch_data, f, indent=2)\n",
    "\n",
    "    torch.save(model.state_dict(),\n",
    "      WEIGHTS_DIR / f\"cp_{epoch}.pth\")\n",
    "  print(f\"\\nValidating final\")\n",
    "  val_filename = f\"val_final.json\"\n",
    "\n",
    "  _, meta = val(dev_dataloader, VALS_DIR / val_filename)\n",
    "\n",
    "  epoch_data[val_filename] = meta\n",
    "  pprint(meta)\n",
    "\n",
    "  print(f\"\\nTesting\")\n",
    "  val_filename = f\"test_final.json\"\n",
    "\n",
    "  _, meta = val(dev_dataloader, VALS_DIR / val_filename)\n",
    "\n",
    "  epoch_data[val_filename] = meta\n",
    "  pprint(meta)\n",
    "\n",
    "  with open(MODEL_ARTIFACTS / \"meta_data.json\", \"w\") as f:\n",
    "    json.dump(epoch_data, f, indent=2)\n",
    "\n",
    "  torch.save(model.state_dict(),\n",
    "    WEIGHTS_DIR / f\"cp_final.pth\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'utterance': 'What periodical literature does Delta Air Lines use as a moutpiece?', 'ents': [{'uri': 'http://www.wikidata.org/entity/Q1002697', 'prefix': 'wd:', 'id': 'Q1002697'}, {'uri': 'http://www.wikidata.org/entity/Q4595717', 'prefix': 'wd:', 'id': 'Q4595717'}, {'uri': 'http://www.wikidata.org/entity/Q6048740', 'prefix': 'wd:', 'id': 'Q6048740'}, {'uri': 'http://www.wikidata.org/entity/Q7300439', 'prefix': 'wd:', 'id': 'Q7300439'}, {'uri': 'http://www.wikidata.org/entity/Q41298', 'prefix': 'wd:', 'id': 'Q41298'}, {'uri': 'http://www.wikidata.org/entity/Q188920', 'prefix': 'wd:', 'id': 'Q188920'}, {'uri': 'http://www.wikidata.org/entity/Q1184780', 'prefix': 'wd:', 'id': 'Q1184780'}, {'uri': 'http://www.wikidata.org/entity/Q1052539', 'prefix': 'wd:', 'id': 'Q1052539'}, {'uri': 'http://www.wikidata.org/entity/Q1658086', 'prefix': 'wd:', 'id': 'Q1658086'}, {'uri': 'http://www.wikidata.org/entity/Q32396', 'prefix': 'wd:', 'id': 'Q32396'}, {'uri': 'http://www.wikidata.org/entity/Q416938', 'prefix': 'wd:', 'id': 'Q416938'}, {'uri': 'http://www.wikidata.org/entity/Q523753', 'prefix': 'wd:', 'id': 'Q523753'}, {'uri': 'http://www.wikidata.org/entity/Q671722', 'prefix': 'wd:', 'id': 'Q671722'}, {'uri': 'http://www.wikidata.org/entity/Q264269', 'prefix': 'wd:', 'id': 'Q264269'}, {'uri': 'http://www.wikidata.org/entity/Q277547', 'prefix': 'wd:', 'id': 'Q277547'}], 'rels': []}, {'utterance': 'What periodical literature does Delta Air Lines use as a moutpiece?', 'fragments': ['[DEF]', 'wd:', 'Q1002697 periodical publication', '[DEF]', 'wd:', 'Q4595717 19th-century Catholic periodical literature', '[DEF]', 'wd:', 'Q6048740 International Bibliography of Periodical Literature', '[DEF]', 'wd:', \"Q7300439 Readers' Guide to Periodical Literature\", '[DEF]', 'wd:', 'Q41298 magazine', '[DEF]', 'wd:', 'Q188920 Delta', '[DEF]', 'wd:', 'Q1184780 Delta Air Lines Flight 191', '[DEF]', 'wd:', 'Q1052539 list of Delta Air Lines destinations', '[DEF]', 'wd:', 'Q1658086 Delta/Delta Heritage Air Park', '[DEF]', 'wd:', 'Q32396 AA', '[DEF]', 'wd:', 'Q416938 Mouthpiece', '[DEF]', 'wd:', 'Q523753 mouthpiece', '[DEF]', 'wd:', 'Q671722 mouthpiece', '[DEF]', 'wd:', 'Q264269 Anna nee Children', '[DEF]', 'wd:', 'Q277547 A&A (disambiguation)']}, {'inputs': \"What periodical literature does Delta Air Lines use as a moutpiece? <extra_id_59> <extra_id_53> Q1002697 periodical publication <extra_id_59> <extra_id_53> Q4595717 19th-century Catholic periodical literature <extra_id_59> <extra_id_53> Q6048740 International Bibliography of Periodical Literature <extra_id_59> <extra_id_53> Q7300439 Readers' Guide to Periodical Literature <extra_id_59> <extra_id_53> Q41298 magazine <extra_id_59> <extra_id_53> Q188920 Delta <extra_id_59> <extra_id_53> Q1184780 Delta Air Lines Flight 191 <extra_id_59> <extra_id_53> Q1052539 list of Delta Air Lines destinations <extra_id_59> <extra_id_53> Q1658086 Delta/Delta Heritage Air Park <extra_id_59> <extra_id_53> Q32396 AA <extra_id_59> <extra_id_53> Q416938 Mouthpiece <extra_id_59> <extra_id_53> Q523753 mouthpiece <extra_id_59> <extra_id_53> Q671722 mouthpiece <extra_id_59> <extra_id_53> Q264269 Anna nee Children <extra_id_59> <extra_id_53> Q277547 A&A (disambiguation)\", 'labels': '<extra_id_6> <extra_id_21> <extra_id_39> <extra_id_19> <extra_id_33> <extra_id_53> q188920 <extra_id_54> p2813 <extra_id_39> <extra_id_38> <extra_id_39> <extra_id_54> p31 <extra_id_53> q1002697 <extra_id_15>'}]\n"
     ]
    }
   ],
   "source": [
    "df_json = []\n",
    "with open(LINKS_PATH) as f:\n",
    "  data_json = json.load(f)\n",
    "\n",
    "print(data_json[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_json = []\n",
    "# with open('weekend.json') as f:\n",
    "#   data_json = json.load(f)\n",
    "\n",
    "for data in data_json:\n",
    "  data_dict = {\n",
    "    \"utterance\": data[0][\"utterance\"],\n",
    "    \"annotated\": data[2][\"inputs\"],\n",
    "    \"gold\": data[2][\"labels\"]\n",
    "  }\n",
    "  df_json.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>annotated</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What periodical literature does Delta Air Line...</td>\n",
       "      <td>What periodical literature does Delta Air Line...</td>\n",
       "      <td>&lt;extra_id_6&gt; &lt;extra_id_21&gt; &lt;extra_id_39&gt; &lt;extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who is the child of Ranavalona Is husband?</td>\n",
       "      <td>Who is the child of Ranavalona Is husband? &lt;ex...</td>\n",
       "      <td>&lt;extra_id_6&gt; &lt;extra_id_39&gt; &lt;extra_id_19&gt; &lt;extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is it true Jeff_Bridges occupation Lane Chandl...</td>\n",
       "      <td>Is it true Jeff_Bridges occupation Lane Chandl...</td>\n",
       "      <td>&lt;extra_id_4&gt; &lt;extra_id_19&gt; &lt;extra_id_33&gt; &lt;extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the pre-requisite of phase matter of G...</td>\n",
       "      <td>What is the pre-requisite of phase matter of G...</td>\n",
       "      <td>&lt;extra_id_6&gt; &lt;extra_id_39&gt; &lt;extra_id_19&gt; &lt;extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which is the operating income for Qantas?</td>\n",
       "      <td>Which is the operating income for Qantas? &lt;ext...</td>\n",
       "      <td>&lt;extra_id_6&gt; &lt;extra_id_21&gt; &lt;extra_id_39&gt; &lt;extr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           utterance  \\\n",
       "0  What periodical literature does Delta Air Line...   \n",
       "1         Who is the child of Ranavalona Is husband?   \n",
       "2  Is it true Jeff_Bridges occupation Lane Chandl...   \n",
       "3  What is the pre-requisite of phase matter of G...   \n",
       "4          Which is the operating income for Qantas?   \n",
       "\n",
       "                                           annotated  \\\n",
       "0  What periodical literature does Delta Air Line...   \n",
       "1  Who is the child of Ranavalona Is husband? <ex...   \n",
       "2  Is it true Jeff_Bridges occupation Lane Chandl...   \n",
       "3  What is the pre-requisite of phase matter of G...   \n",
       "4  Which is the operating income for Qantas? <ext...   \n",
       "\n",
       "                                                gold  \n",
       "0  <extra_id_6> <extra_id_21> <extra_id_39> <extr...  \n",
       "1  <extra_id_6> <extra_id_39> <extra_id_19> <extr...  \n",
       "2  <extra_id_4> <extra_id_19> <extra_id_33> <extr...  \n",
       "3  <extra_id_6> <extra_id_39> <extra_id_19> <extr...  \n",
       "4  <extra_id_6> <extra_id_21> <extra_id_39> <extr...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(df_json)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c8565221d94e2ab53c04ec36b56fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0079a038a542b0b5926ffd58f6b3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2824 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01e0ad291b34bb299dec5123d708125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5649 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202a8e21cca14de2a970a75b2c34320c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d32395a54394418900b38a2b374c054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2824 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81162a543d3c425399542fc9a811e34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5649 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n",
      "\n",
      "Beginning Epoch: 0\n",
      "iteration = 100/1978, training loss=12.247311162948609\n",
      "iteration = 200/1978, training loss=4.075747134685517\n",
      "iteration = 300/1978, training loss=1.8839701735973358\n",
      "iteration = 400/1978, training loss=1.2919707477092743\n",
      "iteration = 500/1978, training loss=1.114117357134819\n",
      "iteration = 600/1978, training loss=1.003723783493042\n",
      "iteration = 700/1978, training loss=0.8742666858434677\n",
      "iteration = 800/1978, training loss=0.7852971810102463\n",
      "iteration = 900/1978, training loss=0.6945610961318016\n",
      "iteration = 1000/1978, training loss=0.6062283045053483\n",
      "iteration = 1100/1978, training loss=0.5530788853764534\n",
      "iteration = 1200/1978, training loss=0.5159430533647538\n",
      "iteration = 1300/1978, training loss=0.4473087468743324\n",
      "iteration = 1400/1978, training loss=0.4231380122900009\n",
      "iteration = 1500/1978, training loss=0.3785054484009743\n",
      "iteration = 1600/1978, training loss=0.3576103523373604\n",
      "iteration = 1700/1978, training loss=0.34262666285037996\n",
      "iteration = 1800/1978, training loss=0.31170577079057693\n",
      "iteration = 1900/1978, training loss=0.12356447599828244\n",
      "Validating epoch 0\n",
      "{'accuracy': '0.0254957507'}\n",
      "\n",
      "Validating final\n",
      "{'accuracy': '0.0254957507'}\n",
      "\n",
      "Testing\n"
     ]
    }
   ],
   "source": [
    "training_loop(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
